{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using PyTorch version: 2.2.0+cpu CUDA: False\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 273\u001b[0m\n\u001b[0;32m    238\u001b[0m     \u001b[38;5;66;03m# # 2 layers, 50 hidden nodes:\u001b[39;00m\n\u001b[0;32m    239\u001b[0m     \u001b[38;5;66;03m# hidden_nodes = 100\u001b[39;00m\n\u001b[0;32m    240\u001b[0m     \u001b[38;5;66;03m# layers = 5\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    269\u001b[0m     \u001b[38;5;66;03m#     plt.ylabel(\"Loss\")\u001b[39;00m\n\u001b[0;32m    270\u001b[0m     \u001b[38;5;66;03m#     plt.show()\u001b[39;00m\n\u001b[0;32m    272\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m--> 273\u001b[0m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[8], line 136\u001b[0m, in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m    131\u001b[0m trainset \u001b[38;5;241m=\u001b[39m torchvision\u001b[38;5;241m.\u001b[39mdatasets\u001b[38;5;241m.\u001b[39mCIFAR10(root\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m./data\u001b[39m\u001b[38;5;124m'\u001b[39m, train\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m    132\u001b[0m                                         download\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, transform\u001b[38;5;241m=\u001b[39mtransform)\n\u001b[0;32m    133\u001b[0m train_loader \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mDataLoader(trainset, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m4\u001b[39m,\n\u001b[0;32m    134\u001b[0m                                           shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, num_workers\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, pin_memory\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m--> 136\u001b[0m testset \u001b[38;5;241m=\u001b[39m \u001b[43mtorchvision\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdatasets\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCIFAR10\u001b[49m\u001b[43m(\u001b[49m\u001b[43mroot\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m./data\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    137\u001b[0m \u001b[43m                                       \u001b[49m\u001b[43mdownload\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtransform\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtransform\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    138\u001b[0m validation_loader \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mDataLoader(testset, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m4\u001b[39m,\n\u001b[0;32m    139\u001b[0m                                          shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, num_workers\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, pin_memory\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m    141\u001b[0m \u001b[38;5;66;03m# hidden_nodes = 100\u001b[39;00m\n\u001b[0;32m    142\u001b[0m \u001b[38;5;66;03m# layers = 1\u001b[39;00m\n\u001b[0;32m    143\u001b[0m \u001b[38;5;66;03m# for i in range(1, len(LEARNING_RATES) + 1):\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    203\u001b[0m \n\u001b[0;32m    204\u001b[0m \u001b[38;5;66;03m# Experimenting w/ different parameters:\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\LEGION\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torchvision\\datasets\\cifar.py:67\u001b[0m, in \u001b[0;36mCIFAR10.__init__\u001b[1;34m(self, root, train, transform, target_transform, download)\u001b[0m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m download:\n\u001b[0;32m     65\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdownload()\n\u001b[1;32m---> 67\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_check_integrity\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataset not found or corrupted. You can use download=True to download it\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     70\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain:\n",
      "File \u001b[1;32mc:\\Users\\LEGION\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torchvision\\datasets\\cifar.py:131\u001b[0m, in \u001b[0;36mCIFAR10._check_integrity\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    129\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m filename, md5 \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_list \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtest_list:\n\u001b[0;32m    130\u001b[0m     fpath \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mroot, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbase_folder, filename)\n\u001b[1;32m--> 131\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[43mcheck_integrity\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmd5\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[0;32m    132\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    133\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\LEGION\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torchvision\\datasets\\utils.py:74\u001b[0m, in \u001b[0;36mcheck_integrity\u001b[1;34m(fpath, md5)\u001b[0m\n\u001b[0;32m     72\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m md5 \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m     73\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m---> 74\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcheck_md5\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmd5\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\LEGION\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torchvision\\datasets\\utils.py:66\u001b[0m, in \u001b[0;36mcheck_md5\u001b[1;34m(fpath, md5, **kwargs)\u001b[0m\n\u001b[0;32m     65\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcheck_md5\u001b[39m(fpath: \u001b[38;5;28mstr\u001b[39m, md5: \u001b[38;5;28mstr\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mbool\u001b[39m:\n\u001b[1;32m---> 66\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m md5 \u001b[38;5;241m==\u001b[39m \u001b[43mcalculate_md5\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\LEGION\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torchvision\\datasets\\utils.py:61\u001b[0m, in \u001b[0;36mcalculate_md5\u001b[1;34m(fpath, chunk_size)\u001b[0m\n\u001b[0;32m     59\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(fpath, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[0;32m     60\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m chunk \u001b[38;5;241m:=\u001b[39m f\u001b[38;5;241m.\u001b[39mread(chunk_size):\n\u001b[1;32m---> 61\u001b[0m         md5\u001b[38;5;241m.\u001b[39mupdate(chunk)\n\u001b[0;32m     62\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m md5\u001b[38;5;241m.\u001b[39mhexdigest()\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import torch\n",
    "import torchvision\n",
    "from torch.autograd import Variable\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Constants\n",
    "IMAGE_WIDTH = 32\n",
    "IMAGE_HEIGHT = 32\n",
    "COLOR_CHANNELS = 3\n",
    "EPOCHS = 300\n",
    "LEARNING_RATES = [.00001, 0.0001, 0.001, 0.01, 0.1]\n",
    "KEEP_RATES = [.5, .65, .8]\n",
    "MOMENTUM_RATES = [.25, .5, .75]\n",
    "WEIGHT_DECAY_RATES = [.0005, .005, .05]\n",
    "BATCH_SIZE = 32\n",
    "BATCH_IMAGE_COUNT = 10000\n",
    "TRAIN_BATCHS = [\"data_batch_1\", \"data_batch_2\", \"data_batch_3\", \"data_batch_4\"]\n",
    "TEST_BATCHES = [\"data_batch_5\"]\n",
    "CLASSES = ['plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n",
    "N_CLASSES = len(CLASSES)\n",
    "PLOT = False\n",
    "\n",
    "\n",
    "\n",
    "class Net(torch.nn.Module):\n",
    "    def __init__(self, n_hidden_nodes, n_hidden_layers, activation, keep_rate=0):\n",
    "        super(Net, self).__init__()\n",
    "        self.n_hidden_nodes = n_hidden_nodes\n",
    "        self.n_hidden_layers = n_hidden_layers\n",
    "        self.activation = activation\n",
    "        if not keep_rate:\n",
    "            keep_rate = 0.5\n",
    "        self.keep_rate = keep_rate\n",
    "        # Set up perceptron layers and add dropout\n",
    "        self.fc1 = torch.nn.Linear(IMAGE_WIDTH * IMAGE_WIDTH * COLOR_CHANNELS,\n",
    "                                   n_hidden_nodes)\n",
    "        self.fc1_drop = torch.nn.Dropout(1 - keep_rate)\n",
    "        self.hidden_layers = torch.nn.ModuleList([\n",
    "            torch.nn.Sequential(\n",
    "                torch.nn.Linear(n_hidden_nodes, n_hidden_nodes),\n",
    "                torch.nn.Dropout(1 - keep_rate)\n",
    "            ) for _ in range(n_hidden_layers - 1)\n",
    "        ])\n",
    "        # Output layer\n",
    "        self.out = torch.nn.Linear(n_hidden_nodes, N_CLASSES)\n",
    "\n",
    "    def forward(self, x):\n",
    "    # Flatten the input tensor\n",
    "        x = x.view(-1, IMAGE_WIDTH * IMAGE_WIDTH * COLOR_CHANNELS)\n",
    "        \n",
    "        # Select activation function dynamically\n",
    "        if self.activation == \"sigmoid\":\n",
    "            activation_fn = torch.nn.Sigmoid()\n",
    "        elif self.activation == \"relu\":\n",
    "            activation_fn = torch.nn.functional.relu\n",
    "\n",
    "        # Apply input layer transformation and activation\n",
    "        if self.activation == \"sigmoid\":\n",
    "            x = activation_fn(self.fc1(x))  # Sigmoid expects to be instantiated\n",
    "        else:\n",
    "            x = activation_fn(self.fc1(x))  # ReLU is functional and does not need instantiation\n",
    "        x = self.fc1_drop(x)\n",
    "\n",
    "        # Apply transformations for hidden layers\n",
    "        for layer in self.hidden_layers:\n",
    "            if self.activation == \"sigmoid\":\n",
    "                x = activation_fn(layer[0](x))\n",
    "            else:\n",
    "                x = activation_fn(layer[0](x))\n",
    "            x = layer[1](x)  # Apply dropout\n",
    "\n",
    "        # Output layer\n",
    "        x = self.out(x)\n",
    "        return torch.nn.functional.log_softmax(x, dim=1)\n",
    "\n",
    "\n",
    " \n",
    "def train(epoch, model, train_loader, optimizer, log_interval=100, cuda=None):\n",
    "    model.train()\n",
    "    correct = 0\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        if cuda:\n",
    "            data, target = data.cuda(), target.cuda()\n",
    "        data, target = Variable(data), Variable(target)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "\n",
    "        pred = output.data.max(1)[1] # get the index of the max log-probability\n",
    "        correct += pred.eq(target.data).cpu().sum()\n",
    "        accuracy = 100. * correct / len(train_loader.dataset)\n",
    "        loss = torch.nn.functional.nll_loss(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if batch_idx % log_interval == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f} Accuracy: {}'.format(\n",
    "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                100. * batch_idx / len(train_loader), loss.item(), accuracy))\n",
    "\n",
    "def validate(loss_vector, accuracy_vector, model, validation_loader, cuda=None):\n",
    "    model.eval()\n",
    "    val_loss, correct = 0, 0\n",
    "    for data, target in validation_loader:\n",
    "        if cuda:\n",
    "            data, target = data.cuda(), target.cuda()\n",
    "        data, target = Variable(data, volatile=True), Variable(target)\n",
    "        output = model(data)\n",
    "        val_loss += torch.nn.functional.nll_loss(output, target).item() # sum up batch loss\n",
    "        pred = output.data.max(1)[1] # get the index of the max log-probability\n",
    "        correct += pred.eq(target.data).cpu().sum()\n",
    "\n",
    "    val_loss /= len(validation_loader)\n",
    "    loss_vector.append(val_loss)\n",
    "\n",
    "    accuracy = 100. * correct / len(validation_loader.dataset)\n",
    "    accuracy_vector.append(accuracy)\n",
    "\n",
    "    print('\\nValidation set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        val_loss, correct, len(validation_loader.dataset), accuracy))\n",
    "\n",
    "def main():\n",
    "    cuda = torch.cuda.is_available()\n",
    "    print('Using PyTorch version:', torch.__version__, 'CUDA:', cuda)\n",
    "\n",
    "    transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "    trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
    "                                            download=True, transform=transform)\n",
    "    train_loader = torch.utils.data.DataLoader(trainset, batch_size=4,\n",
    "                                              shuffle=True, num_workers=0, pin_memory=False)\n",
    "\n",
    "    testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
    "                                           download=True, transform=transform)\n",
    "    validation_loader = torch.utils.data.DataLoader(testset, batch_size=4,\n",
    "                                             shuffle=False, num_workers=0, pin_memory=False)\n",
    "\n",
    "    # hidden_nodes = 100\n",
    "    # layers = 1\n",
    "    # for i in range(1, len(LEARNING_RATES) + 1):\n",
    "    #     model = Net(hidden_nodes, layers, \"sigmoid\")\n",
    "    #     if cuda:\n",
    "    #         model.cuda()\n",
    "    #     optimizer = torch.optim.SGD(model.parameters(), lr=LEARNING_RATES[i-1])\n",
    "\n",
    "    #     loss_vector = []\n",
    "    #     acc_vector = []\n",
    "    #     for epoch in range(1, EPOCHS + 1):\n",
    "    #         train(epoch, model, train_loader, optimizer, cuda=cuda)\n",
    "    #         validate(loss_vector, acc_vector, model, validation_loader, cuda=cuda)\n",
    "    #         if epoch == 25:\n",
    "    #             break\n",
    "\n",
    "    #     # Plot train loss and validation accuracy vs epochs for each learning rate\n",
    "    #     if PLOT:\n",
    "    #         epochs = [i for i in range(1, 26)]\n",
    "    #         plt.plot(epochs, acc_vector)\n",
    "\n",
    "    #         plt.xlabel(\"Epochs\")\n",
    "    #         plt.ylabel(\"Accuracy with Sigmoid\")\n",
    "    #         plt.show()\n",
    "\n",
    "    #         plt.plot(epochs, loss_vector)\n",
    "    #         plt.xlabel(\"Epochs\")\n",
    "    #         plt.ylabel(\"Loss\")\n",
    "    #         plt.show()\n",
    "\n",
    "    # Repeat using RELU for activation\n",
    "\n",
    "    # hidden_nodes = 100\n",
    "    # layers = 1\n",
    "    # start_time = time.time()\n",
    "    # for i in range(1, len(LEARNING_RATES) + 1):\n",
    "    #     model = Net(hidden_nodes, layers, \"relu\")\n",
    "    #     if cuda:\n",
    "    #         model.cuda()\n",
    "    #     optimizer = torch.optim.SGD(model.parameters(), lr=LEARNING_RATES[i-1])\n",
    "\n",
    "    #     loss_vector = []\n",
    "    #     acc_vector = []\n",
    "    #     for epoch in range(1, EPOCHS + 1):\n",
    "    #         train(epoch, model, train_loader, optimizer, cuda=cuda)\n",
    "    #         validate(loss_vector, acc_vector, model, validation_loader, cuda=cuda)\n",
    "    #         if epoch == 25:\n",
    "    #             break\n",
    "    #     end_time = time.time() - start_time\n",
    "    #     print(\"Total time\", end_time)\n",
    "    #     # Plot train loss and validation accuracy vs epochs for each learning rate\n",
    "    #     if PLOT:\n",
    "    #         epochs = [i for i in range(1, 26)]\n",
    "    #         plt.plot(epochs, acc_vector)\n",
    "    #         plt.xlabel(\"Epochs\")\n",
    "    #         plt.ylabel(\"Accuracy with RELU\")\n",
    "    #         plt.show()\n",
    "\n",
    "    #         plt.plot(epochs, loss_vector)\n",
    "    #         plt.xlabel(\"Epochs\")\n",
    "    #         plt.ylabel(\"Loss\")\n",
    "    #         plt.show()\n",
    "\n",
    "    # Experimenting w/ different parameters:\n",
    "\n",
    "    hidden_nodes = 100\n",
    "    layers = 3\n",
    "    start_time = time.time()\n",
    "    for i in range(1, len(KEEP_RATES) + 1):\n",
    "        model = Net(hidden_nodes, layers, \"relu\", keep_rate=KEEP_RATES[i-1])\n",
    "        if cuda:\n",
    "            model.cuda()\n",
    "        optimizer = torch.optim.SGD(model.parameters(), lr=LEARNING_RATES[2], momentum=MOMENTUM_RATES[1], weight_decay=WEIGHT_DECAY_RATES[0])\n",
    "\n",
    "        loss_vector = []\n",
    "        acc_vector = []\n",
    "        for epoch in range(1, EPOCHS + 1):\n",
    "            train(epoch, model, train_loader, optimizer, cuda=cuda)\n",
    "            validate(loss_vector, acc_vector, model, validation_loader, cuda=cuda)\n",
    "        \n",
    "        end_time = time.time() - start_time\n",
    "        print(\"Total time\", end_time)\n",
    "        # Plot train loss and validation accuracy vs epochs for each learning rate\n",
    "        if PLOT:\n",
    "            epochs = [i for i in range(1, 21)]\n",
    "            plt.plot(epochs, acc_vector)\n",
    "            plt.xlabel(\"Epochs\")\n",
    "            plt.ylabel(\"Accuracy with RELU\")\n",
    "            plt.show()\n",
    "\n",
    "            plt.plot(epochs, loss_vector)\n",
    "            plt.xlabel(\"Epochs\")\n",
    "            plt.ylabel(\"Loss\")\n",
    "            plt.show()\n",
    "\n",
    "\n",
    "\n",
    "    # # 2 layers, 50 hidden nodes:\n",
    "    # hidden_nodes = 100\n",
    "    # layers = 5\n",
    "    # start_time = time.time()\n",
    "\n",
    "    # model = Net(hidden_nodes, layers, \"relu\", keep_rate=.8)\n",
    "    # if cuda:\n",
    "    #     model.cuda()\n",
    "    # optimizer = torch.optim.SGD(model.parameters(), lr=LEARNING_RATES[2])\n",
    "\n",
    "    # loss_vector = []\n",
    "    # acc_vector = []\n",
    "    # for epoch in range(1, EPOCHS + 1):\n",
    "    #     train(epoch, model, train_loader, optimizer, cuda=cuda)\n",
    "    #     validate(loss_vector, acc_vector, model, validation_loader, cuda=cuda)\n",
    "    #     if epoch == 30:\n",
    "    #         break\n",
    "    # end_time = time.time() - start_time\n",
    "    # print(\"Total time\", end_time)\n",
    "\n",
    "    # Plot train loss and validation accuracy vs epochs for each learning rate\n",
    "    # if PLOT:\n",
    "    #     epochs = [i for i in range(1, 31)]\n",
    "    #     plt.plot(epochs, acc_vector)\n",
    "\n",
    "    #     plt.xlabel(\"Epochs\")\n",
    "    #     plt.ylabel(\"Accuracy\")\n",
    "    #     plt.show()\n",
    "\n",
    "    #     plt.plot(epochs, loss_vector)\n",
    "    #     plt.xlabel(\"Epochs\")\n",
    "    #     plt.ylabel(\"Loss\")\n",
    "    #     plt.show()\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
